{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE PREPROCESSING**"
      ],
      "metadata": {
        "id": "DMBUmG1TwTdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT THE NECESSARY LIBRARIES**"
      ],
      "metadata": {
        "id": "ORebiLFJhpxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i-FsICHjqUV_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from skimage import feature \n",
        "from imutils import build_montages \n",
        "from imutils import paths\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import os \n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PATH FOR TRAIN AND TEST DATA"
      ],
      "metadata": {
        "id": "GbW6LJDPiCmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jthymE6Zgth",
        "outputId": "a0ef6cbb-f80e-4650-91b6-ed6b62d432d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingpath=r\"/content/drive/My Drive/dataset/spiral/training\"  \n",
        "testingpath=r\"/content/drive/My Drive/dataset/spiral/testing\""
      ],
      "metadata": {
        "id": "JG9660iRXenK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUANTIFYING IMAGES"
      ],
      "metadata": {
        "id": "itQTp14UiL98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantify_image(image):\n",
        "    features = feature.hog(image, orientations=9,\n",
        "                           pixels_per_cell=(10, 10), \n",
        "                           cells_per_block=(2, 2),\n",
        "                           transform_sqrt=True, \n",
        "                           block_norm=\"L1\")\n",
        "    return features"
      ],
      "metadata": {
        "id": "DUxDqb5LXp7T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING TRAIN DATA AND TEST DATA"
      ],
      "metadata": {
        "id": "Icg0VqBXiQQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split(path):\n",
        "  #grab the list of img in the input directory, the initialize the list of data images and class labels\n",
        "  imagePaths = list(paths.list_images (path))\n",
        "  data=[]\n",
        "  labels=[]\n",
        "  #loop over the image paths \n",
        "  for imagePath in imagePaths:\n",
        "    #extract the class label from the filename \n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    #load the input image, convert it to grayscale, and resize # it to 200x200 pixels, ignoring aspect ratio\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (200, 200))\n",
        "    #threshold the image such that the drawing appears as white on a black background\n",
        "    image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2. THRESH_OTSU) [1]\n",
        "    features = quantify_image(image) # quantify the image \n",
        "    data.append(features)\n",
        "    labels.append(label)#update the data and labels lists, respectively \n",
        "  return (np.array(data), np.array(labels))"
      ],
      "metadata": {
        "id": "UX2vhQMYXsrw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading data...\")\n",
        "(X_train, y_train) = load_split(trainingpath)\n",
        "(X_test, y_test) = load_split(testingpath)\n"
      ],
      "metadata": {
        "id": "IeLQT8bFqafJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac44fe6-7aca-41f7-bbad-823f9c813eaf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL ENCODING"
      ],
      "metadata": {
        "id": "NenFHL_nibvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "print(X_train.shape,y_train.shape)\n"
      ],
      "metadata": {
        "id": "3PASDzwpuCnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10620aac-2fa4-4f60-b8b9-975f79645acd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 12996) (72,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL BUILDING**"
      ],
      "metadata": {
        "id": "1sMfDYuMilm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "mWbLWD-jipOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] training model\")\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOWDrnoVcKwe",
        "outputId": "1ff6f4e1-9be4-463c-e050-58ad6f18f37b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING THE MODEL"
      ],
      "metadata": {
        "id": "rclzziGYivCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testingpath=list(paths.list_images(testingpath))\n",
        "idxs=np.arange(0,len(testingpath))\n",
        "idxs=np.random.choice(idxs,size=(25,),replace=False)\n",
        "images=[]"
      ],
      "metadata": {
        "id": "esJlRcUCcNcf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "for i in idxs:\n",
        "    image=cv2.imread(testingpath[i])\n",
        "    output=image.copy()\n",
        "        \n",
        "    # load the input image,convert to grayscale and resize\n",
        "    \n",
        "    output=cv2.resize(output,(128,128))\n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    image=cv2.resize(image,(200,200))\n",
        "    image=cv2.threshold(image,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "    \n",
        "    #quantify the image and make predictions based on the  extracted feature using last trained random forest\n",
        "    features=quantify_image(image)\n",
        "    preds=model.predict([features])\n",
        "    label=le.inverse_transform(preds)[0]\n",
        "    #the set of output images\n",
        "    if label==\"healthy\":\n",
        "        color=(0,255,0)\n",
        "    else:\n",
        "        color=(0,0,255)\n",
        "        \n",
        "    cv2.putText(output,label,(3,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
        "    images.append(output)\n",
        "\n",
        "#creating a montage\n",
        "montage=build_montages(images,(128,128),(5,5))[0]\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB3IyYBQcUS3",
        "outputId": "d3cdafbe-a90f-40fb-f490-49008dba3859"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL EVALUATION"
      ],
      "metadata": {
        "id": "n8H-LP1AiylC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions).flatten()\n",
        "print(cm)\n",
        "(tn, fp, fn, tp) = cm\n",
        "accuracy = (tp + tn) / float(cm.sum())\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "EojibJi0wQw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193cfea5-a36f-42ae-9586-dd3d6a092fea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14  1  3 12]\n",
            "0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVE THE MODEL"
      ],
      "metadata": {
        "id": "6AQrWsA5i1Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model,open('parkinson.pkl','wb')) "
      ],
      "metadata": {
        "id": "qJSQLLrgeAGn"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}